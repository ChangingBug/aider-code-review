"""
é—®é¢˜è§£ææœåŠ¡

è§£æ Aider è¾“å‡ºï¼Œæå–ç»“æ„åŒ–é—®é¢˜ä¿¡æ¯
"""
import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from enum import Enum


class IssueSeverity(Enum):
    """é—®é¢˜ä¸¥é‡ç¨‹åº¦"""
    CRITICAL = "critical"    # ğŸ”´ ä¸¥é‡
    WARNING = "warning"      # ğŸŸ¡ è­¦å‘Š
    SUGGESTION = "suggestion"  # ğŸ”µ å»ºè®®
    INFO = "info"            # â„¹ï¸ ä¿¡æ¯


@dataclass
class ParsedIssue:
    """è§£æåçš„é—®é¢˜"""
    severity: IssueSeverity
    title: str
    description: str
    file_path: Optional[str] = None
    line_number: Optional[int] = None
    code_snippet: Optional[str] = None
    suggestion: Optional[str] = None
    category: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "severity": self.severity.value,
            "title": self.title,
            "description": self.description,
            "file_path": self.file_path,
            "line_number": self.line_number,
            "code_snippet": self.code_snippet,
            "suggestion": self.suggestion,
            "category": self.category,
        }


@dataclass
class ReviewSummary:
    """å®¡æŸ¥æ€»ç»“"""
    overall_score: float
    verdict: str  # é€šè¿‡/éœ€æ”¹è¿›/éœ€é‡ç‚¹å…³æ³¨
    key_findings: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)
    risk_level: str = "low"  # low/medium/high
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "overall_score": self.overall_score,
            "verdict": self.verdict,
            "key_findings": self.key_findings,
            "recommendations": self.recommendations,
            "risk_level": self.risk_level,
        }


class IssueParser:
    """é—®é¢˜è§£æå™¨"""
    
    # ä¸¥é‡ç¨‹åº¦å…³é”®è¯æ˜ å°„
    SEVERITY_PATTERNS = {
        IssueSeverity.CRITICAL: [
            r'ğŸ”´', r'ä¸¥é‡', r'critical', r'security', r'vulnerability',
            r'æ¼æ´', r'å±é™©', r'dangerous', r'error', r'é”™è¯¯'
        ],
        IssueSeverity.WARNING: [
            r'ğŸŸ¡', r'è­¦å‘Š', r'warning', r'æ³¨æ„', r'caution', r'é—®é¢˜'
        ],
        IssueSeverity.SUGGESTION: [
            r'ğŸ”µ', r'å»ºè®®', r'suggestion', r'ä¼˜åŒ–', r'æ”¹è¿›', 
            r'recommend', r'improvement', r'consider'
        ],
        IssueSeverity.INFO: [
            r'â„¹ï¸', r'ä¿¡æ¯', r'info', r'note', r'æç¤º'
        ],
    }
    
    # é—®é¢˜ç±»åˆ«å…³é”®è¯
    CATEGORY_PATTERNS = {
        "security": [r'security', r'å®‰å…¨', r'æ³¨å…¥', r'injection', r'xss', r'csrf', r'æ¼æ´'],
        "logic": [r'é€»è¾‘', r'logic', r'bug', r'ç¼ºé™·', r'é”™è¯¯'],
        "performance": [r'æ€§èƒ½', r'performance', r'ä¼˜åŒ–', r'æ•ˆç‡', r'æ…¢'],
        "style": [r'é£æ ¼', r'style', r'æ ¼å¼', r'å‘½å', r'naming', r'å¯è¯»æ€§'],
        "maintainability": [r'å¯ç»´æŠ¤', r'maintainability', r'å¤æ‚åº¦', r'é‡å¤', r'è€¦åˆ'],
        "documentation": [r'æ–‡æ¡£', r'æ³¨é‡Š', r'comment', r'documentation'],
    }
    
    def parse_report(self, raw_report: str) -> List[ParsedIssue]:
        """è§£æå®¡æŸ¥æŠ¥å‘Šï¼Œæå–ç»“æ„åŒ–é—®é¢˜åˆ—è¡¨"""
        if not raw_report:
            return []
        
        # é¢„å¤„ç†ï¼šç§»é™¤ <think>...</think> æ ‡ç­¾å†…å®¹
        import re
        cleaned_report = re.sub(r'<think>[\s\S]*?</think>', '', raw_report, flags=re.IGNORECASE)
        cleaned_report = re.sub(r'\[think\][\s\S]*?\[/think\]', '', cleaned_report, flags=re.IGNORECASE)
        
        issues = []
        
        # å°è¯•å¤šç§è§£æç­–ç•¥
        issues = self._parse_structured_format(cleaned_report)
        
        if not issues:
            issues = self._parse_markdown_format(cleaned_report)
        
        if not issues:
            issues = self._parse_free_text(cleaned_report)
        
        return issues
    
    def _parse_structured_format(self, text: str) -> List[ParsedIssue]:
        """è§£æç»“æ„åŒ–æ ¼å¼ï¼ˆå¸¦æœ‰æ˜ç¡®æ ‡è®°çš„é—®é¢˜åˆ—è¡¨ï¼‰"""
        issues = []
        
        # åŒ¹é…æ¨¡å¼: ğŸ”´/ğŸŸ¡/ğŸ”µ [æ–‡ä»¶:è¡Œå·] æ ‡é¢˜
        pattern = r'([ğŸ”´ğŸŸ¡ğŸ”µâ„¹ï¸])\s*(?:\[([^\]]+?)(?::(\d+))?\])?\s*(.+?)(?:\n|$)'
        
        for match in re.finditer(pattern, text):
            emoji, file_path, line_num, title = match.groups()
            
            # ç¡®å®šä¸¥é‡ç¨‹åº¦
            severity = self._detect_severity(emoji + " " + title)
            
            # æå–åç»­æè¿°
            start_pos = match.end()
            description = self._extract_description(text, start_pos)
            
            # æå–å»ºè®®
            suggestion = self._extract_suggestion(description)
            
            # æå–ä»£ç ç‰‡æ®µ
            code_snippet = self._extract_code_snippet(description)
            
            # ç¡®å®šç±»åˆ«
            category = self._detect_category(title + " " + description)
            
            issues.append(ParsedIssue(
                severity=severity,
                title=title.strip(),
                description=description.strip() if description else "",
                file_path=file_path,
                line_number=int(line_num) if line_num else None,
                code_snippet=code_snippet,
                suggestion=suggestion,
                category=category,
            ))
        
        return issues
    
    def _parse_markdown_format(self, text: str) -> List[ParsedIssue]:
        """è§£æ Markdown æ ¼å¼ï¼ˆæ ‡é¢˜ + æè¿°ï¼‰"""
        issues = []
        
        # æ–¹æ¡ˆ1ï¼šåŒ¹é… ### æˆ– ## æ ‡é¢˜
        sections = re.split(r'\n(?=#{1,4}\s)', text)
        
        for section in sections:
            if not section.strip():
                continue
            
            # æå–æ ‡é¢˜
            title_match = re.match(r'#{1,4}\s*(.+)', section)
            if not title_match:
                continue
            
            title = title_match.group(1).strip()
            description = section[title_match.end():].strip()
            
            # è·³è¿‡é€šç”¨æ ‡é¢˜ï¼ˆå¦‚"ä»£ç å®¡æŸ¥æŠ¥å‘Š"ã€"æ€»ç»“"ç­‰ï¼‰
            skip_titles = ['ä»£ç å®¡æŸ¥', 'æ€»ç»“', 'summary', 'æ¦‚è¿°', 'overview', 'å®¡æŸ¥æŠ¥å‘Š', 'ç»“è®º']
            if any(skip in title.lower() for skip in skip_titles):
                continue
            
            # æ£€æŸ¥æ˜¯å¦åƒé—®é¢˜æè¿°
            severity = self._detect_severity(title + " " + description)
            if severity == IssueSeverity.INFO and not self._looks_like_issue(title, description):
                continue
            
            # æå–æ–‡ä»¶è·¯å¾„å’Œè¡Œå·
            file_path, line_num = self._extract_file_location(title + " " + description)
            
            issues.append(ParsedIssue(
                severity=severity,
                title=title,
                description=description,
                file_path=file_path,
                line_number=line_num,
                code_snippet=self._extract_code_snippet(description),
                suggestion=self._extract_suggestion(description),
                category=self._detect_category(title + " " + description),
            ))
        
        # æ–¹æ¡ˆ2ï¼šåŒ¹é…æ•°å­—åˆ—è¡¨æ ¼å¼ï¼ˆ1. xxx  2. xxxï¼‰
        if not issues:
            list_pattern = r'(?:^|\n)(\d+)[.ã€]\s*(.+?)(?=\n\d+[.ã€]\s|\n\n|$)'
            for match in re.finditer(list_pattern, text, re.DOTALL):
                content = match.group(2).strip()
                if len(content) < 10:
                    continue
                    
                # æå–ç¬¬ä¸€è¡Œä½œä¸ºæ ‡é¢˜
                lines = content.split('\n')
                title = lines[0][:100]
                description = '\n'.join(lines[1:]) if len(lines) > 1 else ''
                
                severity = self._detect_severity(content)
                if severity == IssueSeverity.INFO and not self._looks_like_issue(title, content):
                    continue
                
                file_path, line_num = self._extract_file_location(content)
                
                issues.append(ParsedIssue(
                    severity=severity,
                    title=title,
                    description=description,
                    file_path=file_path,
                    line_number=line_num,
                    code_snippet=self._extract_code_snippet(content),
                    suggestion=self._extract_suggestion(content),
                    category=self._detect_category(content),
                ))
        
        return issues
    
    def _parse_free_text(self, text: str) -> List[ParsedIssue]:
        """è§£æè‡ªç”±æ–‡æœ¬ï¼ˆä½œä¸ºå•ä¸ªé—®é¢˜æˆ–æŒ‰æ®µè½æ‹†åˆ†ï¼‰"""
        issues = []
        
        # æŒ‰åŒæ¢è¡Œåˆ†æ®µ
        paragraphs = re.split(r'\n\n+', text)
        
        for para in paragraphs:
            if len(para.strip()) < 20:  # å¤ªçŸ­çš„æ®µè½è·³è¿‡
                continue
            
            severity = self._detect_severity(para)
            
            # åªä¿ç•™çœ‹èµ·æ¥åƒé—®é¢˜çš„æ®µè½
            if severity != IssueSeverity.INFO or self._looks_like_issue("", para):
                # æå–ç¬¬ä¸€å¥ä½œä¸ºæ ‡é¢˜
                first_sentence = re.split(r'[ã€‚.!ï¼\n]', para)[0]
                
                issues.append(ParsedIssue(
                    severity=severity,
                    title=first_sentence[:100] + ("..." if len(first_sentence) > 100 else ""),
                    description=para,
                    file_path=None,
                    line_number=None,
                    code_snippet=self._extract_code_snippet(para),
                    suggestion=self._extract_suggestion(para),
                    category=self._detect_category(para),
                ))
        
        return issues
    
    def _detect_severity(self, text: str) -> IssueSeverity:
        """æ£€æµ‹é—®é¢˜ä¸¥é‡ç¨‹åº¦"""
        text_lower = text.lower()
        
        for severity, patterns in self.SEVERITY_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, text_lower, re.IGNORECASE):
                    return severity
        
        return IssueSeverity.INFO
    
    def _detect_category(self, text: str) -> Optional[str]:
        """æ£€æµ‹é—®é¢˜ç±»åˆ«"""
        text_lower = text.lower()
        
        for category, patterns in self.CATEGORY_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, text_lower, re.IGNORECASE):
                    return category
        
        return None
    
    def _looks_like_issue(self, title: str, description: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦çœ‹èµ·æ¥åƒé—®é¢˜æè¿°"""
        combined = (title + " " + description).lower()
        
        issue_indicators = [
            r'should', r'could', r'å»ºè®®', r'å¯ä»¥', r'éœ€è¦',
            r'é—®é¢˜', r'issue', r'bug', r'error', r'warning',
            r'fix', r'ä¿®å¤', r'æ”¹è¿›', r'ä¼˜åŒ–'
        ]
        
        return any(re.search(pat, combined) for pat in issue_indicators)
    
    def _extract_description(self, text: str, start_pos: int) -> str:
        """æå–é—®é¢˜æè¿°ï¼ˆä»èµ·å§‹ä½ç½®åˆ°ä¸‹ä¸€ä¸ªé—®é¢˜æ ‡è®°ï¼‰"""
        # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªé—®é¢˜æ ‡è®°
        next_match = re.search(r'[ğŸ”´ğŸŸ¡ğŸ”µâ„¹ï¸]|\n##', text[start_pos:])
        
        if next_match:
            return text[start_pos:start_pos + next_match.start()]
        return text[start_pos:start_pos + 500]  # æœ€å¤š500å­—ç¬¦
    
    def _extract_suggestion(self, text: str) -> Optional[str]:
        """æå–å»ºè®®ä¿®æ”¹"""
        patterns = [
            r'å»ºè®®[ï¼š:]\s*(.+?)(?:\n|$)',
            r'suggestion[ï¼š:]\s*(.+?)(?:\n|$)',
            r'æ¨è[ï¼š:]\s*(.+?)(?:\n|$)',
            r'åº”è¯¥[ï¼š:]\s*(.+?)(?:\n|$)',
            r'æ”¹ä¸º[ï¼š:]\s*(.+?)(?:\n|$)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return None
    
    def _extract_code_snippet(self, text: str) -> Optional[str]:
        """æå–ä»£ç ç‰‡æ®µ"""
        # åŒ¹é…ä»£ç å—
        code_match = re.search(r'```[\w]*\n([\s\S]*?)```', text)
        if code_match:
            return code_match.group(1).strip()
        
        # åŒ¹é…è¡Œå†…ä»£ç 
        inline_codes = re.findall(r'`([^`]+)`', text)
        if inline_codes:
            return "\n".join(inline_codes[:3])  # æœ€å¤š3ä¸ª
        
        return None
    
    def _extract_file_location(self, text: str) -> tuple:
        """æå–æ–‡ä»¶è·¯å¾„å’Œè¡Œå·"""
        # å¸¸è§æ ¼å¼: file.py:123, file.py line 123, file.py (line 123)
        patterns = [
            r'([a-zA-Z0-9_./\\-]+\.[a-zA-Z]+)[:\s]+(?:line\s*)?(\d+)',
            r'([a-zA-Z0-9_./\\-]+\.[a-zA-Z]+)\s*\(\s*(?:line\s*)?(\d+)\s*\)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1), int(match.group(2))
        
        # ä»…æ–‡ä»¶è·¯å¾„
        file_match = re.search(r'([a-zA-Z0-9_./\\-]+\.[a-zA-Z]{2,4})', text)
        if file_match:
            return file_match.group(1), None
        
        return None, None
    
    def generate_summary(self, issues: List[ParsedIssue], quality_score: float = None) -> ReviewSummary:
        """ç”Ÿæˆå®¡æŸ¥æ€»ç»“"""
        if not issues and quality_score is None:
            return ReviewSummary(
                overall_score=100,
                verdict="é€šè¿‡",
                key_findings=["æœªå‘ç°é—®é¢˜"],
                recommendations=[],
                risk_level="low"
            )
        
        # ç»Ÿè®¡é—®é¢˜
        critical_count = sum(1 for i in issues if i.severity == IssueSeverity.CRITICAL)
        warning_count = sum(1 for i in issues if i.severity == IssueSeverity.WARNING)
        suggestion_count = sum(1 for i in issues if i.severity == IssueSeverity.SUGGESTION)
        
        # è®¡ç®—è¯„åˆ†ï¼ˆå¦‚æœæ²¡æœ‰æä¾›ï¼‰
        if quality_score is None:
            quality_score = max(0, 100 - (critical_count * 20 + warning_count * 5 + suggestion_count * 1))
        
        # ç¡®å®šè¯„ä»·ç»“è®º
        if critical_count > 0:
            verdict = "éœ€é‡ç‚¹å…³æ³¨"
            risk_level = "high"
        elif warning_count > 2:
            verdict = "éœ€æ”¹è¿›"
            risk_level = "medium"
        elif quality_score >= 80:
            verdict = "é€šè¿‡"
            risk_level = "low"
        else:
            verdict = "éœ€æ”¹è¿›"
            risk_level = "medium"
        
        # ç”Ÿæˆå…³é”®å‘ç°
        key_findings = []
        if critical_count > 0:
            key_findings.append(f"å‘ç° {critical_count} ä¸ªä¸¥é‡é—®é¢˜éœ€è¦ç«‹å³ä¿®å¤")
        if warning_count > 0:
            key_findings.append(f"å‘ç° {warning_count} ä¸ªè­¦å‘Šéœ€è¦å…³æ³¨")
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        categories = {}
        for issue in issues:
            if issue.category:
                categories[issue.category] = categories.get(issue.category, 0) + 1
        
        if categories:
            top_category = max(categories, key=categories.get)
            key_findings.append(f"ä¸»è¦é—®é¢˜ç±»å‹: {top_category} ({categories[top_category]} ä¸ª)")
        
        # ç”Ÿæˆå»ºè®®
        recommendations = []
        if critical_count > 0:
            recommendations.append("ä¼˜å…ˆä¿®å¤æ ‡è®°ä¸ºä¸¥é‡çš„å®‰å…¨å’Œé€»è¾‘é—®é¢˜")
        if "security" in categories:
            recommendations.append("è¿›è¡Œå®‰å…¨å®¡æŸ¥ï¼Œç¡®ä¿æ²¡æœ‰æ³¨å…¥é£é™©")
        if "style" in categories:
            recommendations.append("è€ƒè™‘å¼•å…¥ä»£ç æ ¼å¼åŒ–å·¥å…·ç»Ÿä¸€é£æ ¼")
        if suggestion_count > 3:
            recommendations.append("è€ƒè™‘é‡æ„ä»¥æé«˜ä»£ç å¯ç»´æŠ¤æ€§")
        
        return ReviewSummary(
            overall_score=quality_score,
            verdict=verdict,
            key_findings=key_findings if key_findings else ["ä»£ç è´¨é‡è‰¯å¥½"],
            recommendations=recommendations if recommendations else ["ç»§ç»­ä¿æŒè‰¯å¥½çš„ç¼–ç ä¹ æƒ¯"],
            risk_level=risk_level
        )


# å•ä¾‹
issue_parser = IssueParser()
